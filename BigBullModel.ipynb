{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK84/Dt9j4UL6dCbfIjSSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhibrat/Retrieval-Augmented-Generation/blob/main/BigBullModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "spMg1pqrCVTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4jDckilUDRz"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pymilvus langchain openai tiktoken pypdf langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.zilliz import Zilliz\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.prompts import PromptTemplate\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "# 1. Set up the name of the collection to be created.\n",
        "COLLECTION_NAME = 'BigBull'\n",
        "\n",
        "# 2. Set up the dimension of the embeddings.\n",
        "DIMENSION = 1536\n",
        "\n",
        "# 3. Set up the cohere api key\n",
        "OPENAI_API_KEY = userdata.get('openai_api_key')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# 4. Set up the connection parameters for your Zilliz Cloud cluster.\n",
        "URI = 'https://in03-a26a5bfdf5dee2c.api.gcp-us-west1.zillizcloud.com'\n",
        "\n",
        "# 5. Set up the token for your Zilliz Cloud cluster.\n",
        "# You can either use an API key or a set of cluster username and password joined by a colon.\n",
        "TOKEN = userdata.get('zilliz_token')\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=150,\n",
        "    initial_indent=\" \" * 4,\n",
        "    subsequent_indent=\" \" * 4,\n",
        "    break_long_words=False,\n",
        "    break_on_hyphens=False)\n",
        "\n",
        "# print(wrapper.fill(string))"
      ],
      "metadata": {
        "id": "z1-rAPB0Ulov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e05bf70c-b265-4eb8-8c0e-8702aefb9e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.document import Document\n",
        "\n",
        "# all_splits =  [Document(page_content=\"I am Abhi\", metadata={\"source\": \"local\",\"title\":\"Identification\",\"language\":\"en\"})]\n",
        "\n",
        "# loader = WebBaseLoader([\n",
        "#     'https://github.com/donnemartin/system-design-primer'\n",
        "\n",
        "# ])\n",
        "\n",
        "# docs = loader.load()\n",
        "\n",
        "# from bs4 import BeautifulSoup as Soup\n",
        "\n",
        "# from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "\n",
        "# url = \"https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md\"\n",
        "# loader = RecursiveUrlLoader(\n",
        "#     url=url, max_depth=6, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        "# )\n",
        "# docs = loader.load()\n",
        "\n",
        "# docs = [Document(page_content=docs[0].page_content, metadata={\"source\": \"local\",\"title\":\"System Design\",\"language\":\"en\"})]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DE974St8VBQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"http://www.bseindia.com/xml-data/corpfiling/AttachHis/d0467d0f-3fee-4fe4-bbb1-eaaa5b48a2e9.pdf\")\n",
        "\n",
        "docs=[]\n",
        "for doc in loader.load():\n",
        "  docs.append(doc)\n",
        "print(len(docs))\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "H0DAJuBAWB62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSCDrHKR443P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into smaller chunks\n",
        "docs=[]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "# print(docs)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "connection_args = { 'uri': URI, 'token': TOKEN }\n",
        "\n",
        "# vector_store = Zilliz(\n",
        "#     embedding_function=embeddings,\n",
        "#     connection_args=connection_args,\n",
        "#     collection_name=COLLECTION_NAME,\n",
        "#     drop_old=False,\n",
        "#     primary_field=\"pk\"\n",
        "# ).from_documents(\n",
        "#     all_splits,\n",
        "#     embedding=embeddings,\n",
        "#     collection_name=COLLECTION_NAME,\n",
        "#     connection_args=connection_args,\n",
        "# )\n",
        "\n",
        "vector_store = Zilliz(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args=connection_args,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    drop_old=False,\n",
        "    primary_field=\"pk\")\n",
        "# ).from_documents(\n",
        "#     all_splits,\n",
        "#     embedding=embeddings,\n",
        "#     collection_name=COLLECTION_NAME,\n",
        "#     connection_args=connection_args,\n",
        "# )"
      ],
      "metadata": {
        "id": "r9gvMzu0Vxy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"orchid\"\n",
        "docs = vector_store.similarity_search(query)\n",
        "\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "AbzbW0rdk9oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# Use three sentences maximum and keep the answer as concise as possible.\n",
        "# Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. Don't give short answers.\n",
        "Please give as detailed an answer as possible.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "rag_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "response=rag_chain.invoke(\"what are the key focus areas for ashiana housing?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q81jlKq7ezaW",
        "outputId": "9dee8e62-8498-40da-fd1b-fdda21426e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(wrapper.fill(response.content))\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "WSQe2l_t__Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader([\n",
        "    'https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md'\n",
        "\n",
        "])\n",
        "\n",
        "docs = loader.load()\n",
        "docs"
      ],
      "metadata": {
        "id": "ZAoLrnQH-nSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as Soup\n",
        "\n",
        "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md\"\n",
        "loader = RecursiveUrlLoader(\n",
        "    url=url, max_depth=4, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        ")\n",
        "docs = loader.load()\n"
      ],
      "metadata": {
        "id": "p4_T91LjCpqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "id": "Djsv77-OGv7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)\n",
        "\n",
        "# Use three sentences maximum and keep the answer as concise as possible.\n",
        "# Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "template = \"\"\"Don't give short answers.\n",
        "Please give as detailed an answer as possible.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "rag_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "response=rag_chain.invoke(\"explain with code and maths and simple example how the softmax function works\")\n",
        "print(wrapper.fill(response.content))\n"
      ],
      "metadata": {
        "id": "I7gHu0g3GNqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R68W7V1SGO1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}